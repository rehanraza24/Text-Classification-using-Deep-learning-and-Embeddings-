There are multiple Notebooks, i have tried to cover all areas of Text classification. As Accuracy varies due to datasets but Overall Results are good if we improve, we can get better results. <br>

In Notebook [imdb-sentiment-analysis](https://github.com/rehanraza44/Text-Classification-using-Deep-learning-and-Embeddings-/blob/main/imdb-sentiment-analysis.ipynb) i did preprocessing and after that i built RNN-LSTM model with Google-Pretrained Word2vec: 
In Notebook [Deep neural networks Sentiment Analysis](https://github.com/rehanraza44/Text-Classification-using-Deep-learning-and-Embeddings-/blob/main/Deep%20neural%20networks%20Sentiment%20Analysis.ipynb) I have compared all neural networks for Text classification, i explained that how we can improve data<br>
It is main notebook, where we can learn that how we can improve Text Classification models using ## Simple RNN's ## Word Embeddings ## LSTM's ## GRU's ## BI-Directional RNN's <br>
In Notebook [Sarcasm Detection](https://github.com/rehanraza44/Text-Classification-using-Deep-learning-and-Embeddings-/blob/main/Sarcasm%20Detection.ipynb) it is very short version where i have just built Keras models and i made accuracy loss graphs.

Overall i can say, in Text classification there are a lot of things we can consider including visualization, We can improve our accuracy using Advance techinques like Pretrained models, Pretrain-embeddings, So in kaggle i also tried to make better classification models on [Spam Ham Classification](https://www.kaggle.com/muhammadrehan444/spam-ham-classification-98) and [Bidirectional LSTM Toxic Comment Classification](https://www.kaggle.com/muhammadrehan444/bidirectional-lstm-toxic-comment-classification)


